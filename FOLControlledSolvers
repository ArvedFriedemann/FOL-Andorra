Solving Process controlled via FOL terms

As soon as a fact in an FOL formula is deduced, it could be used to perform some computation. For example, if the fact (x = t), where x is a variable and t is a term, is deduced, the variable can directly be assigned in the memory, possibly triggering new deductions. Furthermore, any possible deduction that can be made will be made. From all statements A -> B, B is deduced if A holds, from A v B, B is deduced if A does not hold (or vice versa) and all universal quantifiers are applied to all variables. As one can imagine, especially that last past quickly becomes computationally quite expensive. It is a bit dampened by the fact that only the facts that still might make a change are evaluated. So, when for a quantifier "forall X Y . A = X -> Y", the X is substituted by a B, the substituted term "forall Y . A = B -> Y" would evaluate to TOP already and not further substituted. Still, a lot of facts might be deduced that are not exactly needed. That is why furthermore, only facts that have a proof they are needed are evaluated actively (if passive information is deduced in the meantime it can be used by other deductions). In order to get these proofs, the whole formula is wrapped in somewhat of a monad. The idea is that there is a (kind of) deterministic state that checks which facts need evaluation. For every deduction step, each fact has a variable stating whether this fact needs to be evaluated or not. The variables that contain this information can be deduced as well. Let's say a certain variable needs to be deduced, so it has its needed variable set to TOP. Now, either the variable has been set already and all is good, or one of the facts that result in the deduction of this variable with an implication has to be deduced.

Of course, it is not always unique what the next step is. At the very end, it is always rolling a dice if parallelism is not an option. The question is: Which deduction information is deducible and how does one learn from previous steps; especially how to learn new universal rules?

First things first: When would the deduction of a new universal rule be marked as needed? The algorithm would always eventually find the goal without any further optimisations. But it would not find the goal necessarily in any reasonable amount of time. Let's imagine the algorithm would always perform the unit propagation. In that case, as soon as a shortcut is known it would be taken. So why scout for new shortcuts? There could be a rule that whenever there is a chance of speed enhancement it needs to be taken eventually. This would imply that also some scouting for new rules is done. New rules are mainly deduced by substituting one universal quantifier into the variables of another. --TODO: What about the disjunction case? -- . Every rule would have some performance tradeoff assigned within the current context. If the rule does make things faster than it slags the computational resources for existing it is kept, otherwise it is removed. Axioms cannot be removed.
